{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3bff572a-454d-4ef9-b08c-eaf9bb3a75c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import face_recognition\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b28d8578-70f9-4fe3-b1a8-c66266a71cff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Ahmed Ramzy', 'faysal Qrishi', 'Nour Elshrief']\n"
     ]
    }
   ],
   "source": [
    "#faces_images/Basma.jpg\n",
    "#Face_Recognition/faces_images\n",
    "paths=os.listdir(\"Face_Recognition/faces_images\")\n",
    "\n",
    "imgs_list=paths[1:]\n",
    "#print(imgs_list)\n",
    "for index,i in enumerate(imgs_list):\n",
    "    imgs_list[index]=f\"Face_Recognition/faces_images/{i}\"\n",
    "names=[]\n",
    "encodings=[]\n",
    "for i in imgs_list:\n",
    "    name=os.path.splitext(i)[0]\n",
    "    name=name.split(\"/\")[2]\n",
    "    names.append(name)\n",
    "    i = cv2.imread(i)\n",
    "    rgb_img = cv2.cvtColor(i, cv2.COLOR_BGR2RGB)\n",
    "    enc=face_recognition.face_encodings(rgb_img)[0]\n",
    "    encodings.append(enc)    \n",
    "#print(encodings)\n",
    "print(names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f5a5de65-1563-47a2-9cf8-c91a5d98d1d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nour Elshrief\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "def comparison(input_image):\n",
    "    name=\"Unknown person\"\n",
    "    img2 = cv2.imread(input_image)\n",
    "    rgb_img2 = cv2.cvtColor(img2, cv2.COLOR_BGR2RGB)\n",
    "    rgb_img2=cv2.resize(rgb_img2,(500,500))\n",
    "    face_locations = face_recognition.face_locations(rgb_img2)\n",
    "    y1, x2, y2, x1 = face_locations[0][0], face_locations[0][1], face_locations[0][2], face_locations[0][3]\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    img_encoding2 = face_recognition.face_encodings(rgb_img2)[0]\n",
    "    #print(img_encoding2)\n",
    "    j=0\n",
    "    for i in encodings:\n",
    "         result=face_recognition.compare_faces([i],img_encoding2)\n",
    "         #print(result)\n",
    "         if result==[True]:\n",
    "             name=names[j]\n",
    "             break\n",
    "         j+=1\n",
    "    cv2.putText(rgb_img2, name,(x1, y1 - 10), cv2.FONT_HERSHEY_DUPLEX, 1, (0, 0, 200), 2)\n",
    "    cv2.rectangle(rgb_img2, (x1, y1), (x2, y2), (0, 0, 200), 4)\n",
    "    cv2.imshow(\"image\", rgb_img2)\n",
    "    cv2.waitKey(0)\n",
    "    return name\n",
    "\n",
    "print(comparison(\"Face_Recognition/n.jpg\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "33e6b88f-c680-4c88-ae03-802db384ba2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def comparison(input_image):\n",
    "    name=\"Unknown person\"\n",
    "    #img2 = cv2.imread(input_image)\n",
    "    rgb_img2 = cv2.cvtColor(input_image, cv2.COLOR_BGR2RGB)\n",
    "    face_locations = face_recognition.face_locations(rgb_img2)\n",
    "    if face_locations:\n",
    "        y1, x2, y2, x1 = face_locations[0][0], face_locations[0][1], face_locations[0][2], face_locations[0][3]\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "        img_encoding2 = face_recognition.face_encodings(rgb_img2)[0]\n",
    "    #print(img_encoding2)\n",
    "        \n",
    "        for index,i in enumerate(encodings):\n",
    "             result=face_recognition.compare_faces([i],img_encoding2)\n",
    "         #print(result)\n",
    "             if result==[True]:\n",
    "                 name=names[index]\n",
    "                 break\n",
    "        return(name,(y1, x2, y2, x1))     \n",
    "        \n",
    "    else:return(0)    \n",
    "    \"\"\"else:\n",
    "        #print(\"No faces in the image\")\n",
    "        continue\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "200d2805-701b-4f15-8891-688b73cb0c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "cap.set(3,500)\n",
    "cap.set(4,500)\n",
    "while True:\n",
    "    ret, frame = cap.read()    \n",
    "    frame=cv2.resize(frame,(500,500))\n",
    "\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    result=comparison(frame)\n",
    "    if result!=0:\n",
    "        name,y1, x2, y2, x1=result[0],result[1][0],result[1][1],result[1][2],result[1][3] \n",
    "        cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 0, 200), 4)\n",
    "        if name!=\"Unknown person\":\n",
    "            cv2.putText(frame, name,(x1, y1 - 10), cv2.FONT_HERSHEY_DUPLEX, 1, (0, 0, 200), 2)\n",
    "        #cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 0, 200), 4)\n",
    "    cv2.imshow(\"image\", frame)\n",
    "    k=cv2.waitKey(1)\n",
    "    if k==27:\n",
    "        break\n",
    "    \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "    # Detect Faces\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8574a6-e33f-42ed-a436-1d17bd3df244",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
